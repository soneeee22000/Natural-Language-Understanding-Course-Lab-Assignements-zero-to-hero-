{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa79d934-8c02-49f4-b189-d9cbd9f6e500",
   "metadata": {},
   "source": [
    "# GloVe Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7964c395-6162-436f-b41c-5bb28f2b6074",
   "metadata": {},
   "source": [
    "<b>Name:</b> Pyae Sone Kyaw <b>Student Id:</b> st123225 <b>Course:</b> CS NLU <b>Assignment_2:</b> Glove Assignment <b>Submission Date:</b> 26/1/2023\n",
    "\n",
    "inspired by: Abhniav's and Prof Chalky's code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b269f6c-9a89-48e1-bc49-b74601ca4acc",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e030e2e-8e9c-444f-9078-f3d147788d0d",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation Details\n",
    "use all the models we have learned so far. (skip-gram, skipgram with negative sampling, CBOw and Glove)\n",
    "## assessment\n",
    "use word analogy task dataset to assess the models. (syntactic and semantic accuracy)\n",
    "## corpus \n",
    "use brown corpus. (news category) since it is a large corpus. most of my classmates used it.\n",
    "## preprocessing\n",
    "filter out stopwords and punctuations. (to reduce the vocab size)\n",
    "## vocab size\n",
    "use the first 2000 sentences from the corpus category. (to reduce the vocab size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5435d9a3-a239-489d-8404-07105f810bd9",
   "metadata": {},
   "source": [
    "## similarity dataset\n",
    "use wordsim353_sim_rel dataset. (to check the correlation of the similarity given by the trained models with the similarity score given by the judge for word pairs similarity)\n",
    "## correlation metric\n",
    "use Spearman correlation coefficient with associated p-value. (to check the correlation of the similarity given by the trained models with the similarity score given by the judge for word pairs similarity)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8a17f4-df3b-4f15-8ccf-da33b36c3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e2522-650e-4e5f-8c3a-dd0f81d203ef",
   "metadata": {},
   "source": [
    "## 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41dd1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's load the data and remove all the punctuations and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6edb3205-5f9a-4051-b9da-5ebc24acbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf489a6-52e6-4935-9f7c-f1431ca5a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\pyaes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e990db-089b-4c72-904d-ccf017527b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pyaes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ac0fe4-4b83-460a-bd82-7b0d65275b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed07caf9-d31d-443e-a25d-361a563c634f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d038caf5-0d30-49d3-b5d0-2494c32109d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = []\n",
    "for i in string.punctuation:\n",
    "    punctuations.append(i)\n",
    "punctuations.append(\"''\")\n",
    "punctuations.append('\"\"')\n",
    "punctuations.append('``')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c5edef3-22b6-405d-9db1-c09817e3e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6e985e-d302-4047-8c99-446a83db782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60312bb-0ffd-4583-8570-556737c0babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1dd758-d59e-4376-8b8b-0911f967917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05265fd1-51d8-4959-9e20-21da1cc8f653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'investigation',\n",
       " \"atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " 'evidence',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we list all the stopwords and punctuations above and we are gonna remove them from the corpus\n",
    "corpus_tokenized = brown.sents(categories='news')\n",
    "\n",
    "corpus_tokenized[0]\n",
    "\n",
    "corpus_tokenized = [[word.lower() for word in sent if word not in punctuations and word not in stop_words] for sent in corpus_tokenized]\n",
    "\n",
    "corpus_tokenized[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e58809-5c85-4c40-ae52-fec274808b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4623"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a9f7db-2ec2-49dc-ad91-4839f06b5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokenized = corpus_tokenized[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27730a4e-bbb9-4719-a4f2-5700054be202",
   "metadata": {},
   "source": [
    "## 2) Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77af98-213c-430f-a819-0d5a703cc11d",
   "metadata": {},
   "source": [
    "### Creating vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c093a1-8093-4e28-ad0a-22eee50e6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to flatten this (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))  #vocabs is a term defining all unique words your system know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "409bcfd3-f344-41cd-9153-735e438e75dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comforting', 'consequently', 'streamlined', 'deadline', 'chesapeake', 'nursing', 'bar', 'principal', 'thrill', 'bankers']\n"
     ]
    }
   ],
   "source": [
    "print(vocabs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8915029-ef92-4043-9e98-9c4340c1f60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7323\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size:\", len(vocabs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d613d-5991-490b-a89b-d28c4c8c1ff9",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7cabe9-df19-40ac-99d9-2f9121d1b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {v: idx for idx, v in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80758c68-7eac-4053-b425-b4c0797ea4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocabs.append('<UNK>') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26509dce-4bbb-4bbe-b958-4a88a7cb1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have a way to know what is the id of <UNK>\n",
    "word2index['<UNK>'] = 6  #usually <UNK> is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ae9f5e9-771d-43bc-8b9a-a4de7b868aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create index2word dictionary\n",
    "#2 min    \n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2be3a6d7-d0d1-4b2a-8ee0-9e0ea0444ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5547"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index[\"place\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "701b1e82-007f-45cc-a60c-439e3c106faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bombs'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print one index2word\n",
    "index2word[0]\n",
    "#print another index2word larger \n",
    "index2word[1000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae24f919-b9a1-426e-b03e-0159a6395722",
   "metadata": {},
   "source": [
    "### let's create context and outside words for training the model using skip-gram , skip-gram with negative sampling and golve as instructed in the assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4b50df1-5b3c-4b15-be00-058e0b28587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85dcbf98-af5b-43b2-bae9-61f24a6fd5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4813, 523],\n",
       " [4813, 7301],\n",
       " [4813, 3108],\n",
       " [4813, 2851],\n",
       " [7301, 4813],\n",
       " [7301, 2851],\n",
       " [7301, 523],\n",
       " [7301, 7229],\n",
       " [2851, 7301],\n",
       " [2851, 7229]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgrams = []\n",
    "\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    #for each sent\n",
    "    for i in range(window_size, len(sent) - window_size):\n",
    "        center_word = word2index[sent[i]]\n",
    "        outside_words = []\n",
    "        for j in range(1, window_size + 1):\n",
    "            outside_words.append(word2index[sent[i-j]])\n",
    "            outside_words.append(word2index[sent[i+j]])\n",
    "            \n",
    "        for o in outside_words:\n",
    "            skipgrams.append([center_word, o])\n",
    "\n",
    "skipgrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2a1c1-263d-4fae-861a-4f8da15126ea",
   "metadata": {},
   "source": [
    "### Unigram distribution\n",
    "$$P(w)=U(w)^{3/4}/Z$$\n",
    "\n",
    "Defining the probability of sampling negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dedc033-3002-4770-8b8f-94d7d19f7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8f6fe5f-aacc-4f22-990a-e56eb5c19568",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e13d5e69-3622-4958-9d67-b766498589b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(flatten(corpus_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1902af49-de25-4920-b7a0-fdc9f62434dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23735"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a8c33e-7b57-4e18-ba8b-c752278fba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_table = []\n",
    "\n",
    "for v in vocabs:\n",
    "    uw = word_count[v]/num_total_words\n",
    "    uw_alpha = uw ** 0.75\n",
    "    uw_alpha_dividebyz = int(uw_alpha / z)\n",
    "    # print(\"vocab: \", v)\n",
    "    # print(\"distribution: \", uw_alpha_dividebyz)\n",
    "    unigram_table.extend([v] * uw_alpha_dividebyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a82fa9d2-f27d-4c1d-b29c-767e32b60407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nursing', 'nursing', 'bar', 'principal', 'bankers']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_table[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63e48c0c-90e5-410c-82a6-5b1df9ea4206",
   "metadata": {},
   "source": [
    "### now the pair for context and outside words are ready for training the model using skip-gram , skip-gram with negative sampling and golve as instructed in the assignment . let's move on to CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8138869-5200-4a7b-872c-266e1f55606e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4813, [3108, 523, 7301, 2851]],\n",
       " [7301, [523, 4813, 2851, 7229]],\n",
       " [2851, [4813, 7301, 7229, 2789]],\n",
       " [7229, [7301, 2851, 2789, 1154]],\n",
       " [2789, [2851, 7229, 1154, 6003]],\n",
       " [1154, [7229, 2789, 6003, 2002]],\n",
       " [6003, [2789, 1154, 2002, 7258]],\n",
       " [2002, [1154, 6003, 7258, 4313]],\n",
       " [7258, [6003, 2002, 4313, 5583]],\n",
       " [4313, [2002, 7258, 5583, 895]]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgrams_CBOW = []\n",
    "\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    for i in range(window_size, len(sent) - window_size):\n",
    "        center_word   = word2index[sent[i]]\n",
    "        outside_words = []\n",
    "        \n",
    "        low  = i - window_size\n",
    "        high = i + window_size\n",
    "        for j in range(low, high + 1):\n",
    "            if j == i:\n",
    "                continue\n",
    "            outside_words.append(word2index[sent[j]])\n",
    "        skipgrams_CBOW.append([center_word, outside_words])\n",
    "\n",
    "skipgrams_CBOW[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a0310-f946-4719-8172-a9ea33dc0d81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8fab8eb-a0c5-4391-a00a-f4d0b2015c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to flatten this (basically merge all list)\n",
    "    #vocabs is a term defining all unique words your system know\n",
    "X_i = Counter(flatten(corpus_tokenized)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9c5a1a2-13cd-43a9-a2b8-2478a055044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gloVes = []\n",
    "\n",
    "#loop through each corpus\n",
    "for sent in corpus_tokenized: \n",
    "    #loop through each word from 1 to n-1 (because 0 and n has no context window)\n",
    "    for i in range(1, len(sent)-1):\n",
    "        target  = sent[i]\n",
    "        context = [sent[i+1], sent[i-1]]\n",
    "        #append(i, i+1) and append(i, i-1)\n",
    "        for c in context:\n",
    "            gloVes.append((target, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5060cace-14e6-47f0-a571-b13717ac2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gloVe_id = [(word2index[gloVe[0]], word2index[gloVe[1]]) for gloVe in gloVes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39b3aec9-9f97-4431-8ddb-74282528d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(523, 4813), (523, 3108), (4813, 7301), (4813, 523), (7301, 2851)]\n"
     ]
    }
   ],
   "source": [
    "print(gloVe_id[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a16c951-bf2c-4a9a-bd5c-9ba154272fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have these occurrences, we can count, to make our co-occurrence matrix!!!\n",
    "X_ik_skipgram = Counter(gloVes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27e2adf2-da6f-4473-8cee-c123fe15ea27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik_skipgram[(\"fulton\", \"county\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a533102-c09d-46f5-b82d-7f45bd70c73f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Weighting function f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "102078d2-510d-4465-94e4-cdb3cee61915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i, w_j, X_ik): #X_ik is the co-occurrence matrix\n",
    "    #define x_ij\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1  #why one, so that the probability thingy won't break...(label smoothing)\n",
    "        \n",
    "    #define x_max and alpha\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "    \n",
    "    #define the weighting function\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max) ** alpha\n",
    "    else:\n",
    "        result = 1 #if it's too big, we just set it to 1\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c38fa7f1-4c40-4430-a3f8-7448978ee4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w_i  = 'fulton'\n",
    "w_j  = 'state'\n",
    "w_j2 = 'chaky'\n",
    "\n",
    "print(weighting(w_i, w_j, X_ik_skipgram)) #this is the probability of co-occurrence between fulton and state\n",
    "print(weighting(w_i, w_j2, X_ik_skipgram)) #this is the probability of co-occurrence between fulton and chaky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d6c62f1-c969-4fa6-a025-67901dcd4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now apply this weighting to alcorpus_tokenizedible pairs\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "X_ik = {} #for keeping the co-occurrences\n",
    "weighting_dic = {} #for keeping all the probability after passing through the weighting function\n",
    "\n",
    "for bigram in combinations_with_replacement(vocabs, 2):  #we need to also think its reverse\n",
    "    #if this bigram exists in X_ik_skipgrams\n",
    "    #we gonna add this to our co-occurence matrix\n",
    "    if X_ik_skipgram.get(bigram) is not None:\n",
    "        cooc = X_ik_skipgram[bigram]  #get the co-occurrence\n",
    "        X_ik[bigram] = cooc + 1 #this is again basically label smoothing....(stability issues (especially when divide something))\n",
    "        X_ik[(bigram[1], bigram[0])] = cooc + 1  #trick to get all pairs\n",
    "    else: #otherwise, do nothing\n",
    "        pass\n",
    "    \n",
    "    #apply the weighting function using this co-occurrence matrix thingy    \n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "439da6eb-eb94-46d4-8cf9-58d1634f5cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36226"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_ik_skipgram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35bb9aad-0b63-4c82-b85e-d4ee969e14b1",
   "metadata": {},
   "source": [
    "### create random vectors for the words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fa69015-67ec-4a2f-a309-1a2ab7ae927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, corpus, skip_grams):\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec18c7-30e5-4a38-be7a-3f4696312c1a",
   "metadata": {},
   "source": [
    "<b>Test Function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69469e8e-78cd-4eb2-ba83-22255c07d553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sample: [[   9]\n",
      " [4737]\n",
      " [ 122]\n",
      " [4435]\n",
      " [6087]]\n",
      "Input shape: (5, 1)\n",
      "\n",
      "Label sample: label=array([[6528],\n",
      "       [5294],\n",
      "       [1556],\n",
      "       [1043],\n",
      "       [4891]])\n",
      "Label shape: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch(5, corpus_tokenized, skipgrams)\n",
    "\n",
    "print(\"Input sample:\", input)\n",
    "print(f\"Input shape: {input.shape}\", end=\"\\n\\n\")\n",
    "print(f\"Label sample: {label=}\")\n",
    "print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff1c83b6-469e-4ce1-a838-24323ee7c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting it all together in a function for CBOW\n",
    "def random_batch_cbow(batch_size, corpus, cbow):\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(cbow)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([cbow[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([cbow[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade3116-fc18-44f8-bf1b-cd0b4062dfa8",
   "metadata": {},
   "source": [
    "<b>Test Function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c1ccefd-9564-4550-b288-d3c1234fbac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sample: [[4313]\n",
      " [3813]\n",
      " [5514]\n",
      " [2864]\n",
      " [5621]]\n",
      "Input shape: (5, 1)\n",
      "\n",
      "Label sample: label=array([[2195, 2233, 4533, 1851],\n",
      "       [7171, 6596, 2011, 3620],\n",
      "       [1111, 3512, 2103, 2825],\n",
      "       [7229, 4533, 2711, 4273],\n",
      "       [ 510, 3494, 1006, 6999]])\n",
      "Label shape: (5, 4)\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch_cbow(5, corpus_tokenized, skipgrams_CBOW)\n",
    "\n",
    "print(\"Input sample:\", input)\n",
    "print(f\"Input shape: {input.shape}\", end=\"\\n\\n\")\n",
    "print(f\"Label sample: {label=}\")\n",
    "print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14357b47-095d-406b-bec5-cd161490b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch_gloVe(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
    "    \n",
    "    #loop through this skipgram, and change it id  because when sending model, it must number\n",
    "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    \n",
    "    #randomly pick \"batch_size\" indexes\n",
    "    number_of_choices = len(skip_grams_id)\n",
    "    random_index = np.random.choice(number_of_choices, batch_size, replace=False) #no repeating indexes among these random indexes\n",
    "    \n",
    "    random_inputs = [] #xi, wi (in batches)\n",
    "    random_labels = [] #xj, wj (in batches)\n",
    "    random_coocs  = [] #Xij (in batches)\n",
    "    random_weighting = [] #f(Xij) (in batches)\n",
    "    #for each of the sample in these indexes\n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams_id[i][0]]) #same reason why i put bracket here....\n",
    "        random_labels.append([skip_grams_id[i][1]])\n",
    "        \n",
    "        #get cooc\n",
    "        #first check whether it exists...\n",
    "        pair = skip_grams[i]  #e.g., ('banana', 'fruit)\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1 #label smoothing\n",
    "            \n",
    "        random_coocs.append([math.log(cooc)])  #1. why log, #2, why bracket -> size ==> (, 1)  #my neural network expects (, 1)\n",
    "        \n",
    "        #get weighting\n",
    "        weighting = weighting_dic[pair]  #why not use try....maybe it does not exist....\n",
    "        random_weighting.append(weighting)\n",
    "\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weighting)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97fea7-d989-4a6b-96f2-3b04759a0d0e",
   "metadata": {},
   "source": [
    "<b>Test Function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cd5e928-7869-4ef9-b581-01dbb109d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target, cooc, weightin = random_batch_gloVe(5, corpus_tokenized, gloVes, X_ik, weighting_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1333966-9e6d-4f35-8d7a-effb0f0221e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sample: [[3679]\n",
      " [3899]\n",
      " [4080]\n",
      " [2613]\n",
      " [4806]]\n",
      "Input shape: (5, 1)\n",
      "\n",
      "Label sample: label=array([[2195, 2233, 4533, 1851],\n",
      "       [7171, 6596, 2011, 3620],\n",
      "       [1111, 3512, 2103, 2825],\n",
      "       [7229, 4533, 2711, 4273],\n",
      "       [ 510, 3494, 1006, 6999]])\n",
      "Label shape: (5, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input sample:\", input)\n",
    "print(f\"Input shape: {input.shape}\", end=\"\\n\\n\")\n",
    "print(f\"Label sample: {label=}\")\n",
    "print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73d362cb-6fdf-4266-9fc6-c45e13ccce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3679],\n",
       "        [3899],\n",
       "        [4080],\n",
       "        [2613],\n",
       "        [4806]]),\n",
       " array([[3950],\n",
       "        [4244],\n",
       "        [4554],\n",
       "        [5966],\n",
       "        [5387]]),\n",
       " array([[0.69314718],\n",
       "        [0.69314718],\n",
       "        [0.69314718],\n",
       "        [0.69314718],\n",
       "        [0.69314718]]),\n",
       " array([0.05318296, 0.05318296, 0.05318296, 0.05318296, 0.05318296]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, target, cooc, weightin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db829659-5cc3-4db6-a9ad-99762a68e48a",
   "metadata": {},
   "source": [
    "### create helper function for training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddd114ed-4656-4901-912c-1fb4ad59aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca930f7a-9957-46d7-9181-0879e61daae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#you don't want to pick samples = targets, basically negative samples\n",
    "#k = number of negative samples - how many? they found 10 is the best\n",
    "#will be run during training\n",
    "#after random_batch, \n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    #targets is already in id.....\n",
    "    #but the unigram_table is in word....\n",
    "    #1. get the batch size of this targets\n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    #2. for each batch\n",
    "    for i in range(batch_size):\n",
    "        #randomly pick k negative words from unigram_table\n",
    "        target_index = targets[i].item()  #looping each of the batch....\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            #if this word == target, skip this word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        #append this word to some list\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))  #tensor[], tensor[]\n",
    "    return torch.cat(neg_samples)  #tensor[[], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70824e1-7400-46d4-8e36-e8e9521e4a26",
   "metadata": {},
   "source": [
    "<b>Test Functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63d5b9f6-488b-48df-95a4-f38e98d56316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3052],\n",
       "        [ 148]]),\n",
       " array([[3239],\n",
       "        [3152]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch, label_batch = random_batch(2, corpus_tokenized, skipgrams)\n",
    "\n",
    "input_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f45baca8-112e-4b44-b834-2496481b98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.LongTensor(input_batch)\n",
    "label_batch = torch.LongTensor(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da6ba236-6318-4a79-862c-fb680bb7e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg = 5  #in the real code, we gonna use 10 (like in the paper)\n",
    "neg_samples = negative_sampling(label_batch, unigram_table, num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35f73271-eead-416a-ba07-77a3e47cb8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8d3f4-3cc8-4609-ba7c-b746a16dd0b8",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca1a44-fe4c-41f4-a324-ea227882a7e3",
   "metadata": {},
   "source": [
    "### Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1aa124-534e-4d09-a065-71a7dd46e8a4",
   "metadata": {},
   "source": [
    "$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}}\\log P(w_{t+j} | w_t; \\theta)$$\n",
    "\n",
    "where $P(w_{t+j} | w_t; \\theta) = $\n",
    "\n",
    "$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n",
    "\n",
    "where $o$ is the outside words and $c$ is the center word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c1c207a-90db-4545-966b-734ac8d1bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_w\n",
    "#u_o - vector for outside words\n",
    "#v_c - vector for center word\n",
    "#u_w - vectors of all vocabs\n",
    "\n",
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word, outside_word: (batch_size, 1)\n",
    "        #all_vocabs: (batch_size, voc_size)\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
    "         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9a5ea3e-3215-4048-a261-2bbb74a8495e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7324])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing all_vocabs\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "voc_size = len(vocabs)\n",
    "voc_size\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4970a-db4d-4674-90fb-afce38e2d5f6",
   "metadata": {},
   "source": [
    "<b>Test Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16e4e356-f02e-4018-b26d-805c51380988",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized, skipgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6612c5a8-5de6-4256-96e6-bdab980dabdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3101],\n",
       "        [3593],\n",
       "        [4506],\n",
       "        [2081],\n",
       "        [6785]]),\n",
       " array([[5232],\n",
       "        [5937],\n",
       "        [5268],\n",
       "        [5680],\n",
       "        [3376]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67772a8c-e1de-43a0-80f4-c3487a214942",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2\n",
    "model = Skipgram(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba2a797d-0341-42d2-9ea6-9edd2900d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7946c55a-b2d5-45aa-b5ca-4c0320a588b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4565cdb9-791d-4b68-bbe1-13e40e555f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8243, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d258b61-39b8-4736-b8d3-e507e9c62026",
   "metadata": {},
   "source": [
    "### Skip-gram with negative sampling\n",
    "\n",
    "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15b1c0d4-b1a2-401e-8ae9-1cf68e9b1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNeg(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, center_words, outside_words, negative_words):\n",
    "        #center_words, outside_words: (batch_size, 1)\n",
    "        #negative_words:  (batch_size, k)\n",
    "        \n",
    "        center_embed  = self.embedding_center_word(center_words)    #(batch_size, 1, emb_size)\n",
    "        outside_embed = self.embedding_outside_word(outside_words)  #(batch_size, 1, emb_size)\n",
    "        neg_embed     = self.embedding_outside_word(negative_words) #(batch_size, k, emb_size)\n",
    "        \n",
    "        uovc          =  outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, 1)\n",
    "        ukvc          = -neg_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, k)\n",
    "        ukvc_sum      =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
    "        \n",
    "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)  #(batch_size, 1) + (batch_size, 1)\n",
    "                \n",
    "        return -torch.mean(loss)  #scalar, loss should be scalar, to call backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a2b00-8c4a-4c1b-9a8a-adbaf084dc7e",
   "metadata": {},
   "source": [
    "<b>Test Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7051430e-62da-4354-99ce-22c1a5d0fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized, skipgrams)\n",
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00ee210d-62b8-441a-a160-59ffdb906ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2\n",
    "voc_size = len(vocabs)\n",
    "model = SkipgramNeg(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c122bc0-3e82-4686-9c8e-99acadaaa9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tensor = negative_sampling(label_tensor, unigram_table, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a391509-aedd-45e5-b836-43d8a74e2579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, label_tensor.shape#, neg_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7ce2cbd-7c86-4efb-b66d-a27c7e1a4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(input_tensor, label_tensor, neg_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "938e1d9c-e54e-4899-9df6-2383271083fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1893, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717f2ed-6dad-4b8d-937f-4f1fa9dcba07",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "345e37e0-3860-4852-b836-5da72b62645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_c, u_j, v_mean\n",
    "#u_c - vector for center word from the output word matrix\n",
    "#u_j - vectors for all vocab from the output word matrix\n",
    "#v_mean - mean of the vectors of context words from the input word matrix \n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.input_word  = nn.Embedding(voc_size, emb_size) #v\n",
    "        self.output_word = nn.Embedding(voc_size, emb_size) #u\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word: (batch_size, 1)\n",
    "        #context_words: (batch_size, window_size * 2)\n",
    "        #all_vocabs: (batch_size, voc_size)\n",
    "        batch_size = center_word.shape[0]\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.output_word(center_word)   #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.input_word(outside_word)   #(batch_size, window_size * 2, emb_size)\n",
    "        all_vocabs_embed   = self.output_word(all_vocabs)    #(batch_size, voc_size, emb_size)        \n",
    "        \n",
    "        # mean of input word embeddings\n",
    "        v_mean = torch.sum(outside_word_embed, 1) / len(outside_word) #(batch_size, emb_size)\n",
    "        \n",
    "        ucv = center_word_embed.bmm(v_mean.reshape(batch_size, 1, self.emb_size).transpose(1, 2)).squeeze()\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ==> (batch_size, 1)\n",
    "        \n",
    "        ujv = all_vocabs_embed.bmm(v_mean.reshape(batch_size, 1, self.emb_size).transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size)\n",
    "        \n",
    "        ujv_log_exp = torch.log(torch.exp(ujv))\n",
    "        # (batch_size, voc_size) -> (batch_size,)\n",
    "        \n",
    "        loss_fn = - ucv + torch.sum(ujv_log_exp, 1)\n",
    "        # - (batch_size, 1) + (batch_size, 1) = (batch_size, 1)\n",
    "        \n",
    "        return torch.mean(loss_fn) # scaler for back-propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61409d2a-9b4d-4082-a9b2-8c08103ce878",
   "metadata": {},
   "source": [
    "<b>Test Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e98af1b-4716-4e57-99c3-5a816cafbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(5, voc_size)\n",
    "model = CBOW(voc_size, emb_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "960aa485-b463-4dd6-ae02-33191794f562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([5, 4]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, label = random_batch_cbow(5, corpus_tokenized, skipgrams_CBOW)\n",
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)\n",
    "input_tensor.shape, label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f329d07-eaf9-4095-b68b-97f0fb79c671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4840]), tensor([5644, 5665,  944, 3939]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[0], label_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc1da918-54c5-434c-89e3-6ad813a19815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3047, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3040d20-71e5-4335-8fda-cd6f4ba94d18",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f97bfea2-65e7-4e2b-b0de-0810a6725a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embed_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weighting):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        #note that coocs already got log\n",
    "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489070de-1f3e-4a67-8499-b4f42970593d",
   "metadata": {},
   "source": [
    "<b>Test Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74df0d48-f3d2-4163-af38-539084f1b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target, cooc, weightin = random_batch_gloVe(5, corpus_tokenized, gloVes, X_ik, weighting_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3deea44f-4c3e-498d-a245-aca01073a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2\n",
    "voc_size = len(vocabs)\n",
    "model = GloVe(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2dbb0dca-cda2-4979-ba7a-0b7a2d74c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch    = torch.LongTensor(input)\n",
    "target_batch   = torch.LongTensor(target)\n",
    "cooc_batch     = torch.FloatTensor(cooc)\n",
    "weightin_batch = torch.FloatTensor(weightin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52b4e09e-d818-4dac-9a59-178dcda36d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(input_batch, target_batch, cooc_batch, weightin_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc447d6a-12e6-480d-89c1-023c489060ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5011, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39d504-b001-4e2c-a1bd-239e58d532ed",
   "metadata": {},
   "source": [
    "## 4) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab5e51e4-c114-4197-8d52-3388f72cafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43518021-d2b2-45e0-99b1-53708492cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb95c9-a113-4117-bb94-eb064c282958",
   "metadata": {},
   "source": [
    "### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73e614ef-fcf7-4ac9-9475-f0672429af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size   = 50\n",
    "model1     = Skipgram(voc_size, emb_size)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a7d100c-2b03-4464-83a3-1a5d998c24b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 7324])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9aac3c51-a3da-4f01-9ec7-30060f2e647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 | Loss: 26.595457 | Time: 0.027086973190307617\n",
      "Epoch 500 | Loss: 25.581800 | Time: 0.029000520706176758\n",
      "Epoch 750 | Loss: 29.168341 | Time: 0.029961585998535156\n",
      "Epoch 1000 | Loss: 27.501553 | Time: 0.030039072036743164\n",
      "Epoch 1250 | Loss: 29.165424 | Time: 0.03065776824951172\n",
      "Epoch 1500 | Loss: 27.259912 | Time: 0.02876758575439453\n",
      "Epoch 1750 | Loss: 28.714096 | Time: 0.02934885025024414\n",
      "Epoch 2000 | Loss: 29.096113 | Time: 0.028376102447509766\n",
      "Epoch 2250 | Loss: 27.671209 | Time: 0.026983261108398438\n",
      "Epoch 2500 | Loss: 27.055780 | Time: 0.02785968780517578\n",
      "Epoch 2750 | Loss: 28.731546 | Time: 0.03099226951599121\n",
      "Epoch 3000 | Loss: 26.388475 | Time: 0.0287477970123291\n",
      "Epoch 3250 | Loss: 28.094547 | Time: 0.03195595741271973\n",
      "Epoch 3500 | Loss: 27.826181 | Time: 0.030002832412719727\n",
      "Epoch 3750 | Loss: 26.896601 | Time: 0.028470277786254883\n",
      "Epoch 4000 | Loss: 26.892872 | Time: 0.03127622604370117\n",
      "Epoch 4250 | Loss: 30.907562 | Time: 0.026211261749267578\n",
      "Epoch 4500 | Loss: 27.244144 | Time: 0.02805352210998535\n",
      "Epoch 4750 | Loss: 27.676937 | Time: 0.0266568660736084\n",
      "Epoch 5000 | Loss: 27.089653 | Time: 0.03172779083251953\n",
      "Total trainig time: 146.85005593299866\n"
     ]
    }
   ],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus_tokenized, skipgrams)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    \n",
    "    # print(input_batch.shape, label_batch.shape, all_vocabs.shape)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model1(input_batch, label_batch, all_vocabs)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {total_time}\")\n",
    "        \n",
    "total_training_time = time.time() - train_start_time\n",
    "print(\"Total trainig time:\", total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbe0b8-7b13-47e5-b489-bf9b6fc46ece",
   "metadata": {},
   "source": [
    "### Skip-gram with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed4e0993-60ac-4b6b-92d2-46020f888cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size  = 50\n",
    "model2 = SkipgramNeg(voc_size, emb_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f76f0f70-641b-409d-b374-42a5154566bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 | Loss: 8.205234 | Time: 0.007005929946899414\n",
      "Epoch 500 | Loss: 6.990298 | Time: 0.007039785385131836\n",
      "Epoch 750 | Loss: 6.567665 | Time: 0.007110118865966797\n",
      "Epoch 1000 | Loss: 8.909377 | Time: 0.008394479751586914\n",
      "Epoch 1250 | Loss: 6.478815 | Time: 0.008036613464355469\n",
      "Epoch 1500 | Loss: 8.917675 | Time: 0.007954835891723633\n",
      "Epoch 1750 | Loss: 9.195609 | Time: 0.00767207145690918\n",
      "Epoch 2000 | Loss: 7.721918 | Time: 0.008297204971313477\n",
      "Epoch 2250 | Loss: 9.909580 | Time: 0.007026195526123047\n",
      "Epoch 2500 | Loss: 8.253580 | Time: 0.008241891860961914\n",
      "Epoch 2750 | Loss: 10.001043 | Time: 0.00700831413269043\n",
      "Epoch 3000 | Loss: 9.415213 | Time: 0.009051084518432617\n",
      "Epoch 3250 | Loss: 11.735939 | Time: 0.005998373031616211\n",
      "Epoch 3500 | Loss: 9.457308 | Time: 0.00823354721069336\n",
      "Epoch 3750 | Loss: 11.514767 | Time: 0.00706028938293457\n",
      "Epoch 4000 | Loss: 11.432185 | Time: 0.008025884628295898\n",
      "Epoch 4250 | Loss: 9.038859 | Time: 0.007652997970581055\n",
      "Epoch 4500 | Loss: 8.878803 | Time: 0.007735013961791992\n",
      "Epoch 4750 | Loss: 9.208369 | Time: 0.007012605667114258\n",
      "Epoch 5000 | Loss: 11.424232 | Time: 0.006845951080322266\n",
      "Total trainig time: 37.27279758453369\n"
     ]
    }
   ],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus_tokenized, skipgrams)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    neg_batch   = negative_sampling(label_batch, unigram_table, 5)    \n",
    "    \n",
    "    #loss = model\n",
    "    loss = model2(input_batch, label_batch, neg_batch)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {total_time}\")\n",
    "        \n",
    "total_training_time = time.time() - train_start_time\n",
    "print(\"Total trainig time:\", total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f400d-e50f-40e3-a424-65d504ebe14a",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4730bdd-ce76-404c-877d-54b84f885bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size  = 50\n",
    "model3 = CBOW(voc_size, emb_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98ee837d-04cf-4aa7-ac0d-5d3de219e1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 7324])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca45c69d-7e6f-4e52-8e50-2c19ddccf6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 | Loss: 0.519273 | Time: 0.02568840980529785\n",
      "Epoch 500 | Loss: 9.708236 | Time: 0.023740291595458984\n",
      "Epoch 750 | Loss: -1.130049 | Time: 0.030622243881225586\n",
      "Epoch 1000 | Loss: 9.584751 | Time: 0.028729677200317383\n",
      "Epoch 1250 | Loss: -29.188667 | Time: 0.02927851676940918\n",
      "Epoch 1500 | Loss: 3.678998 | Time: 0.029614686965942383\n",
      "Epoch 1750 | Loss: -1.195722 | Time: 0.027408361434936523\n",
      "Epoch 2000 | Loss: -1.211780 | Time: 0.030165672302246094\n",
      "Epoch 2250 | Loss: -1.421137 | Time: 0.029845237731933594\n",
      "Epoch 2500 | Loss: 0.652337 | Time: 0.02757096290588379\n",
      "Epoch 2750 | Loss: -5.580129 | Time: 0.029867887496948242\n",
      "Epoch 3000 | Loss: -2.801577 | Time: 0.027363061904907227\n",
      "Epoch 3250 | Loss: 5.922264 | Time: 0.027045249938964844\n",
      "Epoch 3500 | Loss: -3.870833 | Time: 0.029249906539916992\n",
      "Epoch 3750 | Loss: -1.101122 | Time: 0.028268814086914062\n",
      "Epoch 4000 | Loss: -2.036714 | Time: 0.027559995651245117\n",
      "Epoch 4250 | Loss: -2.027371 | Time: 0.02759718894958496\n",
      "Epoch 4500 | Loss: 0.250043 | Time: 0.027285099029541016\n",
      "Epoch 4750 | Loss: -5.562626 | Time: 0.027033090591430664\n",
      "Epoch 5000 | Loss: 6.851006 | Time: 0.03000473976135254\n",
      "Total trainig time: 141.96887302398682\n"
     ]
    }
   ],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch_cbow(batch_size, corpus_tokenized, skipgrams_CBOW)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model3(input_batch, label_batch, all_vocabs)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {total_time}\")\n",
    "        \n",
    "total_training_time = time.time() - train_start_time\n",
    "print(\"Total trainig time:\", total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0bf010-a1f1-41bc-8f96-def69699abf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03356942-11dc-4afa-af94-752f9bd37f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size  = 50\n",
    "model4 = GloVe(voc_size, emb_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b63c1a38-1a62-4159-8fea-d6a0162fe2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 | Loss: 1997.681274 | Time: 0.014145135879516602\n",
      "Epoch 500 | Loss: 1937.284180 | Time: 0.010567426681518555\n",
      "Epoch 750 | Loss: 1650.354126 | Time: 0.008912086486816406\n",
      "Epoch 1000 | Loss: 2416.785156 | Time: 0.008843660354614258\n",
      "Epoch 1250 | Loss: 2472.373535 | Time: 0.010133028030395508\n",
      "Epoch 1500 | Loss: 2394.305908 | Time: 0.009006500244140625\n",
      "Epoch 1750 | Loss: 1660.030029 | Time: 0.008988618850708008\n",
      "Epoch 2000 | Loss: 2496.681152 | Time: 0.008260965347290039\n",
      "Epoch 2250 | Loss: 1494.736694 | Time: 0.009389162063598633\n",
      "Epoch 2500 | Loss: 2282.000000 | Time: 0.008575201034545898\n",
      "Epoch 2750 | Loss: 1788.161621 | Time: 0.009713172912597656\n",
      "Epoch 3000 | Loss: 2007.218262 | Time: 0.00727391242980957\n",
      "Epoch 3250 | Loss: 921.957581 | Time: 0.008416175842285156\n",
      "Epoch 3500 | Loss: 2381.812012 | Time: 0.009227991104125977\n",
      "Epoch 3750 | Loss: 1912.392090 | Time: 0.008805274963378906\n",
      "Epoch 4000 | Loss: 2906.250732 | Time: 0.008000850677490234\n",
      "Epoch 4250 | Loss: 2709.157715 | Time: 0.008009195327758789\n",
      "Epoch 4500 | Loss: 1644.585571 | Time: 0.008630990982055664\n",
      "Epoch 4750 | Loss: 1639.534180 | Time: 0.008002758026123047\n",
      "Epoch 5000 | Loss: 2303.044434 | Time: 0.014381170272827148\n",
      "Total trainig time: 43.84301996231079\n"
     ]
    }
   ],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #get random batch\n",
    "    input, target, cooc, weightin = random_batch_gloVe(batch_size, corpus_tokenized, gloVes, X_ik, weighting_dic)\n",
    "    input_batch    = torch.LongTensor(input)\n",
    "    target_batch   = torch.LongTensor(target)\n",
    "    cooc_batch     = torch.FloatTensor(cooc)\n",
    "    weightin_batch = torch.FloatTensor(weightin)\n",
    "        \n",
    "    #loss = model\n",
    "    loss = model4(input_batch, target_batch, cooc_batch, weightin_batch)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {total_time}\")\n",
    "        \n",
    "total_training_time = time.time() - train_start_time\n",
    "print(\"Total trainig time:\", total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a1fef-ebb0-4859-9a0a-27da71019313",
   "metadata": {},
   "source": [
    "## 5) Evaluating Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82f06c8a-091e-456c-8ecc-b132599bd0ea",
   "metadata": {},
   "source": [
    "### Semantic and syntatic Accuracy\n",
    "trying every word in the vocabulary to find the word that has the highest cosine similarity with the vector B - A + C. If the word is in the semantic category of the question, then the accuracy is increased by 1. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35517a53-c536-4697-b202-4eb7fdcee34d",
   "metadata": {},
   "source": [
    "all these models were trained using the first 2000 sentences from the brown corpus category. (to reduce the vocab size) doesn't seems to indentify the missing term correctly for both semantic and syntactic parts. This may be due to limited corpus size and vocabulary. Due to this, another accuracy based on how the correct missing term is ranked based on similarity is used. The average was taken from very analogy task questions for both semantic and syntactic parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "067cd02d-8cca-46ea-87ca-b14b49527370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word, model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.embedding_center_word(word)\n",
    "    outside_embed = model.embedding_outside_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return embed\n",
    "    # return  embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c8e3c9d-d8af-4d4e-a28a-c4c871235883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed(\"man\", model1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4fd4d7ac-6031-4de1-a5e6-13fb309be4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_CBOW(word, model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.input_word(word)\n",
    "    outside_embed = model.output_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return embed\n",
    "    # return  embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9612dec8-4172-4b7f-8930-8bb72d26637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed_CBOW(\"man\", model3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "92d8e606-5863-44a1-af75-467470a2530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_GloVe(word, model):\n",
    "    id_tensor = torch.LongTensor([word2index[word]])\n",
    "    v_embed = model.embedding_v(id_tensor)\n",
    "    u_embed = model.embedding_u(id_tensor) \n",
    "    word_embed = (v_embed + u_embed) / 2 \n",
    "    \n",
    "    return word_embed\n",
    "\n",
    "    # x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
    "    # return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6710af96-8b97-4465-8579-084b68bdc007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed_GloVe(\"man\", model4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67cb991b-af10-4634-88c9-a8cc523f325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f01afa07-97c1-4370-8146-3d2b3ceb39cc",
   "metadata": {},
   "source": [
    "### testing the model using questions-words.txt dataset \n",
    "### modifying the dataset to fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d8e8147-97c6-4fe9-ae63-11453559727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open and load the questions-words.txt file\n",
    "with open('questions-words.txt', 'r') as f:\n",
    "    questions = f.readlines()\n",
    "\n",
    "#remove the first 5 lines\n",
    "questions = questions[5:]\n",
    "\n",
    "#remove the last 2 lines\n",
    "questions = questions[:-2]\n",
    "\n",
    "#remove the new line character\n",
    "questions = [q.strip() for q in questions]\n",
    "\n",
    "#remove the empty lines\n",
    "questions = [q for q in questions if q]\n",
    "\n",
    "#split the questions into 4 parts\n",
    "questions = [q.split(' ') for q in questions]\n",
    "\n",
    "#remove the colon\n",
    "questions = [q[1:] for q in questions]\n",
    "\n",
    "#remove the last word\n",
    "questions = [q[:-1] for q in questions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46004fd4-0e0d-4902-aaf1-172775122e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = {}\n",
    "key         = None\n",
    "value       = []\n",
    "with open('questions-words.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == \":\":\n",
    "            if key != None:\n",
    "                testDataset[key] = value\n",
    "            key   = line.strip()\n",
    "            value = []\n",
    "            continue\n",
    "        value.append(line.strip().lower())\n",
    "    testDataset[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce8ced12-d840-45d0-907c-fd1efb1e4410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2c18e02-9761-443a-a825-91bb0ddb6ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([': capital-common-countries', ': capital-world', ': currency', ': city-in-state', ': family', ': gram1-adjective-to-adverb', ': gram2-opposite', ': gram3-comparative', ': gram4-superlative', ': gram5-present-participle', ': gram6-nationality-adjective', ': gram7-past-tense', ': gram8-plural', ': gram9-plural-verbs'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b26a7721-8ce1-448f-99de-84ccf20004b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['athens greece baghdad iraq',\n",
       " 'athens greece bangkok thailand',\n",
       " 'athens greece beijing china',\n",
       " 'athens greece berlin germany',\n",
       " 'athens greece bern switzerland',\n",
       " 'athens greece cairo egypt',\n",
       " 'athens greece canberra australia',\n",
       " 'athens greece hanoi vietnam',\n",
       " 'athens greece havana cuba',\n",
       " 'athens greece helsinki finland']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset[': capital-common-countries'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5008d86-2c9b-47e9-a050-369668880897",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic  = [': capital-common-countries', ': capital-world', ': currency', ': family']\n",
    "syntactic = [': gram1-adjective-to-adverb', ': gram2-opposite', ': gram3-comparative', ': gram4-superlative', \n",
    "             ': gram5-present-participle', ': gram6-nationality-adjective', ': gram7-past-tense', ': gram8-plural', \n",
    "             ': gram9-plural-verbs']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2444c253-fb4d-44b8-8580-1222958afd65",
   "metadata": {},
   "source": [
    "### okay now moving on to semantic accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "192f14a8-3fbc-463e-84c1-97fdcc840de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_syntatic_eval(model, testDict, CBOWMode = False, GloVeMode = False):\n",
    "    total_corr = 0\n",
    "    pairs_used = 0\n",
    "    acc_sum    = 0\n",
    "    \n",
    "    for key in testDict:\n",
    "        pairs = testDataset[key]\n",
    "        # print(pairs[0].split(\" \"))\n",
    "        for pair in pairs:\n",
    "            pair_tokenized = pair.split(\" \")\n",
    "            word_a, word_b, word_c, word_d = pair_tokenized  \n",
    "            if word_a not in word2index or word_b not in word2index or word_c not in word2index or word_d not in word2index:\n",
    "                continue\n",
    "                \n",
    "            word_d_index = vocabs.index(word_d)\n",
    "            \n",
    "            if GloVeMode:\n",
    "                a_embedding = get_embed_GloVe(word_a, model) \n",
    "                b_embedding = get_embed_GloVe(word_b, model)\n",
    "                c_embedding = get_embed_GloVe(word_c, model)\n",
    "            elif CBOWMode:\n",
    "                a_embedding = get_embed_CBOW(word_a, model) \n",
    "                b_embedding = get_embed_CBOW(word_b, model)\n",
    "                c_embedding = get_embed_CBOW(word_c, model)\n",
    "            else:\n",
    "                a_embedding = get_embed(word_a, model) \n",
    "                b_embedding = get_embed(word_b, model)\n",
    "                c_embedding = get_embed(word_c, model)\n",
    "            \n",
    "            AminusBplusC = (b_embedding - a_embedding + c_embedding).squeeze()\n",
    "            \n",
    "            count = -1\n",
    "            similarity_arr = [0] * len(vocabs)\n",
    "            for vocab in vocabs:\n",
    "                count += 1\n",
    "                if vocab in pair_tokenized[:3]:\n",
    "                    continue\n",
    "                \n",
    "                if GloVeMode:\n",
    "                    current = get_embed_GloVe(vocab, model).squeeze()\n",
    "                elif CBOWMode:\n",
    "                    current = get_embed_CBOW(vocab, model).squeeze()\n",
    "                else:\n",
    "                    current = get_embed(vocab, model).squeeze()\n",
    "                similarity_arr[count] = cos_sim(AminusBplusC.detach().numpy(), current.detach().numpy())\n",
    "            \n",
    "            similarity_arr_sorted_index = np.argsort(similarity_arr)\n",
    "            rank                        = np.where(similarity_arr_sorted_index == word_d_index)[0][0]\n",
    "            acc_sum += (rank + 1) / len(vocabs)\n",
    "            \n",
    "            pairs_used += 1\n",
    "            predicted_word = np.argmax(similarity_arr)\n",
    "            if predicted_word == word_d:\n",
    "                total_corr+= 1\n",
    "                \n",
    "    total_acc = total_corr / pairs_used\n",
    "    avg_acc = acc_sum / pairs_used\n",
    "    return total_acc, total_corr, avg_acc, pairs_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf32ded-3562-473f-8a30-37f2f7ea0683",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "993f394e-b1d2-4976-8cf1-afb5f71f6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc, total_corr, avg_acc, pairs_used = semantic_syntatic_eval(model1, semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db8d757a-a822-4965-ae5b-4ce391c5d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.49%\n",
      "Total pairs used: 113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23d09e-1de5-4a01-8a39-c625a38f9d02",
   "metadata": {},
   "source": [
    "##### Skip-gram with negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b489845-c132-49a6-aafb-1c17fe88990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_neg, total_corr_neg, avg_acc_neg, pairs_used_neg = semantic_syntatic_eval(model2, semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ed29cc9-fd53-485a-bd2c-e93082f5bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.44%\n",
      "Total pairs used: 113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc_neg}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc_neg, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8347861-e67c-4283-8237-ff0e37ab2d8c",
   "metadata": {},
   "source": [
    "##### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60fd04b9-f963-4e50-8733-d0c3ecc8b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_cbow, total_corr_cbow, avg_acc_cbow, pairs_used_cbow = semantic_syntatic_eval(model3, semantic, CBOWMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3e25492-cd46-41a4-94ae-14d56fe3ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.5%\n",
      "Total pairs used: 113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc_cbow}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc_cbow, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d329db-f128-4eea-b36f-e477a7f1162d",
   "metadata": {},
   "source": [
    "##### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "341f2f9e-3227-4908-8483-b1d197ebf89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_gloVe, total_corr_gloVe, avg_acc_gloVe, pairs_used_gloVe = semantic_syntatic_eval(model4, semantic, GloVeMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a864e4c-94b8-4568-852d-45cfd04e490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.45%\n",
      "Total pairs used: 113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc_gloVe}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc_gloVe, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used_gloVe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c55cbca5-34e1-4433-a165-1d8d01ed675a",
   "metadata": {},
   "source": [
    "### and now Syntatic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5b1ea-be6b-45e6-9074-4cfdebf3d1cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95b95b0e-eb83-409f-a735-45d75d209424",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc2, total_corr2, avg_acc2, pairs_used2 = semantic_syntatic_eval(model1, syntactic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d452d949-ecf4-4c40-a97c-3d3b0bb8a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.5%\n",
      "Total pairs used: 1108\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc2}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc2, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab445d-4f36-4f3e-aafc-6ef9d045d9d2",
   "metadata": {},
   "source": [
    "##### Skip-gram with negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b7daca42-f575-44ff-b539-348e6fc51010",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_neg2, total_corr_neg2, avg_acc_neg2, pairs_used_neg2 = semantic_syntatic_eval(model2, syntactic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "908b7d37-4b34-4e08-ba22-296618df3d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.47%\n",
      "Total pairs used: 1108\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc_neg2}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc_neg2, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used_neg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5122e9-08bc-40a8-8ecf-6756033b7ceb",
   "metadata": {},
   "source": [
    "##### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03e62aec-5a46-48a9-9051-216ad938caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_cbow2, total_corr_cbow2, avg_acc_cbow2, pairs_used_cbow2 = semantic_syntatic_eval(model3, syntactic, CBOWMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "73b21c2b-c359-40aa-a917-3a9964027247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.51%\n",
      "Total pairs used: 1108\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc_cbow2}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc_cbow2, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used_cbow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d94a0f-26bb-436b-b0ce-453602f21148",
   "metadata": {},
   "source": [
    "##### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08aadc2a-c99d-4a14-8aa4-1e770f330646",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_gloVe2, total_corr_gloVe2, avg_acc_gloVe2, pairs_used_gloVe2 = semantic_syntatic_eval(model4, syntactic, GloVeMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b965c762-2054-4ede-a552-23648fe8ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.0%\n",
      "Average accuracy according to the ranking: 0.5%\n",
      "Total pairs used: 1108\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Accuracy: {total_acc_gloVe2}%\")\n",
    "print(f\"Average accuracy according to the ranking: {round(avg_acc_gloVe2, 2)}%\")\n",
    "print(f\"Total pairs used:\", pairs_used_gloVe2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be322b11-e0d8-476e-9777-195a573fa5ff",
   "metadata": {},
   "source": [
    "### accuracy results for semantic and syntatic parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e9fb22c4-bc7a-4585-9485-d26dc3b21684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9890a243-c035-4a05-b909-1acac852b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pairs_semantic = 0\n",
    "for key in semantic:\n",
    "    total_pairs_semantic += len(testDataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "55f3df4b-3d32-4f52-9a2f-f60f573e68ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs for semantic evaluation: 6402\n",
      "Pairs used for semantic evaluation: 113\n"
     ]
    }
   ],
   "source": [
    "print(\"Total pairs for semantic evaluation:\", total_pairs_semantic)\n",
    "print(\"Pairs used for semantic evaluation:\", pairs_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ca6a0b67-4540-4f54-9f2e-667bfbca7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pairs_syntactic = 0\n",
    "for key in syntactic:\n",
    "    total_pairs_syntactic += len(testDataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f6d7789-e7bc-4b7e-878c-ea31dc8c0b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs for syntactic evaluation: 10675\n",
      "Pairs used for syntactic evaluatio: 1108\n"
     ]
    }
   ],
   "source": [
    "print(\"Total pairs for syntactic evaluation:\", total_pairs_syntactic)\n",
    "print(\"Pairs used for syntactic evaluatio:\", pairs_used2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67128da4-7902-4e08-85d2-005a7d6c0651",
   "metadata": {},
   "source": [
    "### Total Accuracy (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d5ee2d10-49b6-4580-a3f5-96327b3f0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "head    = [\"Model\", \"Semantic\", \"Syntatic\"]\n",
    "content = [\n",
    "    [\"Skip-gram\", total_acc, total_acc2],\n",
    "    [\"Skip-gram with negative sampling\", total_acc_neg, total_acc_neg2],\n",
    "    [\"CBOW\", total_acc_cbow, total_acc_cbow2],\n",
    "    [\"GloVe\", total_acc_gloVe, total_acc_gloVe2]\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a150735f-f727-48c5-8f95-0d2a28467934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+------------+------------+\n",
      "| Model                            |   Semantic |   Syntatic |\n",
      "+==================================+============+============+\n",
      "| Skip-gram                        |          0 |          0 |\n",
      "+----------------------------------+------------+------------+\n",
      "| Skip-gram with negative sampling |          0 |          0 |\n",
      "+----------------------------------+------------+------------+\n",
      "| CBOW                             |          0 |          0 |\n",
      "+----------------------------------+------------+------------+\n",
      "| GloVe                            |          0 |          0 |\n",
      "+----------------------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(content, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e8794b-190e-470d-84ec-34c714efc7e2",
   "metadata": {},
   "source": [
    "### Average Accuracy (%) based on Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "27fbb70f-4452-4fde-bac3-48a9c3410a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "head    = [\"Model\", \"Semantic\", \"Syntatic\"]\n",
    "content = [\n",
    "    [\"Skip-gram\", avg_acc, avg_acc2],\n",
    "    [\"Skip-gram with negative sampling\", avg_acc_neg, avg_acc_neg2],\n",
    "    [\"CBOW\", avg_acc_cbow, avg_acc_cbow2],\n",
    "    [\"GloVe\", avg_acc_gloVe, avg_acc_gloVe2]\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "784b8147-aba2-4ace-9f9a-0534ee39e9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+------------+------------+\n",
      "| Model                            |   Semantic |   Syntatic |\n",
      "+==================================+============+============+\n",
      "| Skip-gram                        |   0.491664 |   0.499768 |\n",
      "+----------------------------------+------------+------------+\n",
      "| Skip-gram with negative sampling |   0.443425 |   0.472926 |\n",
      "+----------------------------------+------------+------------+\n",
      "| CBOW                             |   0.502589 |   0.505397 |\n",
      "+----------------------------------+------------+------------+\n",
      "| GloVe                            |   0.448496 |   0.502787 |\n",
      "+----------------------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(content, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "309255e6-7584-4ffd-ad55-d6d7ed04bbdd",
   "metadata": {},
   "source": [
    "### finally let's check the correlation of the similarity given by the trained models with the similarity score given by the judge for word pairs similarity using wordsim353_sim_rel dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b725adb1-6091-45dd-8904-e47a21e0d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532faa8-c56c-4a94-9158-be37fe0c788b",
   "metadata": {},
   "source": [
    "### Load Similarity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e9214c63-cd2f-4997-95bf-ff7504b8691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordsim353_sim_rel/wordsim_relatedness_goldstandard.txt') as f:\n",
    "    relatedness_db = [line.strip().lower().split(\"\\t\") for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a4ef9992-cd84-41ed-b311-ff704c5aa7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer', 'keyboard', '7.62'],\n",
       " ['jerusalem', 'israel', '8.46'],\n",
       " ['planet', 'galaxy', '8.11'],\n",
       " ['canyon', 'landscape', '7.53'],\n",
       " ['opec', 'country', '5.63'],\n",
       " ['day', 'summer', '3.94'],\n",
       " ['day', 'dawn', '7.53'],\n",
       " ['country', 'citizen', '7.31'],\n",
       " ['planet', 'people', '5.75'],\n",
       " ['environment', 'ecology', '8.81']]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatedness_db[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b5688bc2-122d-4b86-bd27-3f4577c3d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordsim353_sim_rel/wordsim_similarity_goldstandard.txt') as f:\n",
    "    similarity_db = [line.strip().lower().split(\"\\t\") for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "963d7b66-cde7-4d02-a75e-81f83ec54a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tiger', 'cat', '7.35'],\n",
       " ['tiger', 'tiger', '10.00'],\n",
       " ['plane', 'car', '5.77'],\n",
       " ['train', 'car', '6.31'],\n",
       " ['television', 'radio', '6.77'],\n",
       " ['media', 'radio', '7.42'],\n",
       " ['bread', 'butter', '6.19'],\n",
       " ['cucumber', 'potato', '5.92'],\n",
       " ['doctor', 'nurse', '7.00'],\n",
       " ['professor', 'doctor', '6.62']]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_db[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ec2fd73d-ba05-4599-9f2b-e3271b0f8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_eval(dataset, model, CBOWMode = False, GloVeMode = False):\n",
    "    valid_idx     = []\n",
    "    cos_sim_arr   = []\n",
    "    human_val_sim = []\n",
    "    \n",
    "    for idx, pair in enumerate(dataset):\n",
    "        word1, word2, evalHuman = pair\n",
    "        if word1 not in vocabs or word2 not in vocabs:\n",
    "            continue\n",
    "        \n",
    "        if GloVeMode:\n",
    "            word1_embedding = get_embed_GloVe(word1, model)\n",
    "            word2_embedding = get_embed_GloVe(word2, model)\n",
    "        elif CBOWMode:\n",
    "            word1_embedding = get_embed_CBOW(word1, model)\n",
    "            word2_embedding = get_embed_CBOW(word2, model)\n",
    "        else:\n",
    "            word1_embedding = get_embed(word1, model)\n",
    "            word2_embedding = get_embed(word2, model)\n",
    "        \n",
    "        sim_eval = cos_sim(word1_embedding.detach().numpy().squeeze(), word2_embedding.detach().numpy().squeeze())\n",
    "        valid_idx.append(idx)\n",
    "        cos_sim_arr.append(sim_eval)\n",
    "        human_val_sim.append(float(evalHuman))\n",
    "        \n",
    "        res = stats.spearmanr(cos_sim_arr, human_val_sim)\n",
    "    \n",
    "    return valid_idx, cos_sim_arr, human_val_sim, res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e010470-1084-45a3-a749-453e9a490275",
   "metadata": {},
   "source": [
    "### now let's check the correlation of the similarity given by the trained models with the similarity score given by the judge for word pairs similarity using wordsim353_sim_rel dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06fc95c4-8208-4307-ab3d-a66ad028d9a8",
   "metadata": {},
   "source": [
    "spearmans correlation coefficient is used to check the correlation of the similarity given by the trained models with the similarity score given by the judge for word pairs similarity \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912aa5d-e607-4b18-bcf8-1947cc3234f7",
   "metadata": {},
   "source": [
    "##### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "edb2806d-161b-48d5-aeec-3213d1a4d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx, cos_sim_arr, human_val_sim, res = similarity_eval(similarity_db, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "adf7d949-ef37-4f4a-8d1a-fade29b9aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 203\n",
      "Samples used: 78\n",
      "Spearmanr correlation coefficient (rs): -0.0468\n",
      "p-value: 0.6839\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(similarity_db))\n",
    "print(\"Samples used:\", len(valid_idx))\n",
    "print(\"Spearmanr correlation coefficient (rs):\", round(res.correlation,4))\n",
    "print(\"p-value:\", round(res.pvalue,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bac3b-9d16-4bb3-a1ed-12675c1459e4",
   "metadata": {},
   "source": [
    "##### Skip-gram with negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7a666104-9348-49ac-bbcb-51ceb46a314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_neg, cos_sim_arr_neg, human_val_sim_neg, res_neg = similarity_eval(similarity_db, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1f160d21-f558-4f84-9cf4-fee8b31323ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 203\n",
      "Samples used: 78\n",
      "Spearmanr correlation coefficient (rs): -0.0835\n",
      "p-value: 0.4673\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(similarity_db))\n",
    "print(\"Samples used:\", len(valid_idx_neg))\n",
    "print(\"Spearmanr correlation coefficient (rs):\", round(res_neg.correlation,4))\n",
    "print(\"p-value:\", round(res_neg.pvalue,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c8a2f-dba5-493c-b58c-61451298a5a7",
   "metadata": {},
   "source": [
    "##### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b0b05bf3-1a0c-4857-8b94-b4590ad2d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_CBOW, cos_sim_arr_CBOW, human_val_sim_CBOW, res_CBOW = similarity_eval(similarity_db, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7a95138b-adbe-4210-a563-50011b9fcf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 203\n",
      "Samples used: 78\n",
      "Spearmanr correlation coefficient (rs):: -0.0835\n",
      "p-value of Spearmanr: 0.4673\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(similarity_db))\n",
    "print(\"Samples used:\", len(valid_idx_CBOW))\n",
    "print(\"Spearmanr correlation coefficient (rs)::\", round(res_CBOW.correlation,4))\n",
    "print(\"p-value of Spearmanr:\", round(res_CBOW.pvalue,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061743b6-fd73-4319-8a8e-0dc9bd4b7853",
   "metadata": {},
   "source": [
    "##### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4be512e9-1546-4b4d-a12b-2513213e0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_gloVe, cos_sim_arr_gloVe, human_val_sim_gloVe, res_gloVe = similarity_eval(similarity_db, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b3d588a8-45ed-4af2-8cfa-328097082ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 203\n",
      "Samples used: 78\n",
      "Spearmanr correlation coefficient (rs):: -0.0468\n",
      "p-value: 0.6839\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(similarity_db))\n",
    "print(\"Samples used:\", len(valid_idx_gloVe))\n",
    "print(\"Spearmanr correlation coefficient (rs)::\", round(res_gloVe.correlation,4))\n",
    "print(\"p-value:\", round(res_gloVe.pvalue,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31060654-cf12-4b21-8cd7-a39594076fd8",
   "metadata": {},
   "source": [
    "### correlation results for different models using wordsim353_sim_rel dataset \n",
    "\n",
    "### Spearman correlation coefficient with associated p-value for different models :\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "96d6786d-9440-451c-b0f8-cbb7710fb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "head    = [\"Model\", \"rs\", \"p-value\"]\n",
    "content = [\n",
    "    [\"Skip-gram\", round(res.correlation,4), round(res.pvalue,4)],\n",
    "    [\"Skip-gram with negative sampling\", round(res_neg.correlation,4), round(res_neg.pvalue,4)],\n",
    "    [\"CBOW\", round(res_CBOW.correlation,4), round(res_CBOW.pvalue,4)],\n",
    "    [\"GloVe\", round(res_gloVe.correlation,4), round(res_gloVe.pvalue,4)]\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "006f4dc6-0750-4686-ac84-be9d97c91e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+---------+-----------+\n",
      "| Model                            |      rs |   p-value |\n",
      "+==================================+=========+===========+\n",
      "| Skip-gram                        | -0.0468 |    0.6839 |\n",
      "+----------------------------------+---------+-----------+\n",
      "| Skip-gram with negative sampling | -0.0835 |    0.4673 |\n",
      "+----------------------------------+---------+-----------+\n",
      "| CBOW                             | -0.0835 |    0.4673 |\n",
      "+----------------------------------+---------+-----------+\n",
      "| GloVe                            | -0.0468 |    0.6839 |\n",
      "+----------------------------------+---------+-----------+\n",
      "Where rs is Spearman correlation coefficient\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(content, headers=head, tablefmt=\"grid\"))\n",
    "print(\"Where rs is Spearman correlation coefficient\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cbcf190-37e0-4ead-b9ce-2819b801017d",
   "metadata": {},
   "source": [
    "## 6) Conclusion and Discussion "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b64e7ba-e346-4660-820c-c3f4a28270b9",
   "metadata": {},
   "source": [
    "### ---semantic and syntatic accuracy results for different models--- \n",
    "in summary, the skip-gram with negative sampling model seems to perform the best in both semantic and syntatic parts. the skip-gram model seems to perform the best in syntatic part. the CBOW model seems to perform the best in semantic part. the GloVe model seems to perform the best in syntatic part. They all do not perform well in both semantic and syntatic parts. This may be due to limited corpus size and vocabulary. Due to this, another accuracy based on how the correct missing term is ranked based on similarity is used. The average was taken from very analogy task questions for both semantic and syntatic parts. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d6fa78a",
   "metadata": {},
   "source": [
    "### ---correlation results for different models using wordsim353_sim_rel dataset---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5fdb91a-b938-4891-9cdb-aad391e3d5f3",
   "metadata": {},
   "source": [
    "Also for the correlation of the similarity given by the trained models with the similarity score given by the judge for word pairs similarity using wordsim353_sim_rel dataset is not very high, either . This may be due to limited corpus size and vocabulary. Due to this, another accuracy based on how the correct missing term is ranked based on similarity is used. The average was taken from very analogy task questions for both semantic and syntatic parts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a59b473075a889197cef78f691a8dde253fc9cd06ebdea22432c59d124001e4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
